{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyof\n",
    "import csv\n",
    "import plotly.express as pxp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "#importing dataset from file\n",
    "dataset= pd.read_csv('HTTPD_log.csv', names= ['IP', 'identd', 'user_id', 'time', 'time_ext','req_method', 'req_dir', 'req_http_header', 'status_code', 'bytes_trans'])\n",
    "#we only need the IP Address & Status Code\n",
    "dataset= dataset[['IP','status_code']]\n",
    "#modifying dataset by aggregating count of status code against IP Address\n",
    "dataset= dataset.groupby(['IP','status_code']).status_code.agg('count').to_frame('Total').reset_index()\n",
    "#We are inserting the Index No as it needs it, otherwise it will give Shape of passed values is (13, 2), indices imply (13, 3) error\n",
    "dataset.insert(0, 'IndexNo', range(len(dataset)))\n",
    "#we are droping IP Column as instead of this we will take the Index No as reference of IP and scale it\n",
    "train_data= dataset.drop(['IP'], axis= 1)\n",
    "\n",
    "sc= StandardScaler()\n",
    "scaled_data= sc.fit_transform(train_data)\n",
    "#We have used here 5 as a cluster because it's a good practice to give odd number due to the calculation of points which are crucial between two cluster\n",
    "model= KMeans(n_clusters= 5)\n",
    "pred= model.fit_predict(scaled_data)\n",
    "#here IP_Scaled is actually IndexNo because IP Address is treated as string\n",
    "pred_ds= pd.DataFrame(scaled_data, columns= ['IP_Scaled', 'status_code_Scaled','Total_Scaled'])\n",
    "pred_ds['Cluster']= pred\n",
    "ds= pd.concat([dataset, pred_ds], axis= 1, sort= False)\n",
    "#Here we are creating graph of Request per IP vs Count\n",
    "Graph= pxp.scatter(ds, 'Total', 'IP', 'Cluster', hover_data= ['status_code'], color_continuous_scale= 'Jet') \n",
    "layout= go.Layout(title= 'Request/IP', hovermode= 'closest') \n",
    "figure= go.Figure(data= Graph, layout= layout)\n",
    "graph= pyof.plot(figure, filename= 'Cluster_graph.html', auto_open= False)\n",
    "#Here we will see which cluster is violating the number of request against a threshold of 500 \n",
    "black_cluster= []\n",
    "for index, row in ds.iterrows():\n",
    "    if ds['Total'].loc[index] > 500:\n",
    "          black_cluster.append(ds['Cluster'].loc[index])\n",
    "black_cluster= max(set(black_cluster), key= black_cluster.count)\n",
    "#Here we have created a CSV file which will keep record for all the IP which are under blacklist cluster\n",
    "filename= \"DoS_Blacklist.csv\"\n",
    "with open(filename, '+w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['IP_Blacklist']) \n",
    "    for index_in_data, row_in_data in ds.iterrows():\n",
    "        if ds['Cluster'].loc[index_in_data] == black_cluster:\n",
    "            #Check whether we have the IP already in the file\n",
    "            if ds['IP'].loc[index_in_data] not in np.array(csvfile): \n",
    "                csvwriter.writerows([[ds['IP'].loc[index_in_data]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
